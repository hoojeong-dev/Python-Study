{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab2-5.pose_action_recognition.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8icTZWPQEKt"
      },
      "source": [
        "# 2-5. Pose Estimation, Action Recognition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrWWdl1vP--u"
      },
      "source": [
        "!pip3 install --upgrade mxnet-cu101 > /dev/null\r\n",
        "!pip3 install --upgrade gluoncv > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zwYA8s5srbC"
      },
      "source": [
        "## Pose Estimation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWjnU3cMSbqz"
      },
      "source": [
        "### Pose Estimation Framework\r\n",
        "<img src='https://res.infoq.com/articles/human-pose-estimation-ai-powered-fitness-apps/en/resources/30image001-1602703271382.jpg' width=100% />\r\n",
        "\r\n",
        "- heatmap\r\n",
        "\r\n",
        "<img src='https://res.infoq.com/articles/human-pose-estimation-ai-powered-fitness-apps/en/resources/25image003-1602703274021.jpg' />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tyExQiUQV9k"
      },
      "source": [
        "### Simple Pose Estimation\r\n",
        "- input size : 256*192"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYaQkfmNQaWh"
      },
      "source": [
        "from matplotlib import pyplot as plt\r\n",
        "from gluoncv import model_zoo, data, utils\r\n",
        "from gluoncv.data.transforms.pose import detector_to_simple_pose, heatmap_to_coord"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5CaUWsbQa6H"
      },
      "source": [
        "detector = model_zoo.get_model('yolo3_mobilenet1.0_coco', pretrained=True)\r\n",
        "pose_net = model_zoo.get_model('simple_pose_resnet18_v1b', pretrained=True)\r\n",
        "\r\n",
        "# Note that we can reset the classes of the detector to only include\r\n",
        "# human, so that the NMS process is faster.\r\n",
        "\r\n",
        "detector.reset_class([\"person\"], reuse_weights=['person'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iz3HttpeQi1T"
      },
      "source": [
        "im_fname = utils.download('https://github.com/dmlc/web-data/blob/master/' +\r\n",
        "                          'gluoncv/pose/soccer.png?raw=true',\r\n",
        "                          path='soccer.png')\r\n",
        "x, img = data.transforms.presets.ssd.load_test(im_fname, short=512)\r\n",
        "print('Shape of pre-processed image:', x.shape)\r\n",
        "\r\n",
        "class_IDs, scores, bounding_boxs = detector(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIfhX2moQjOy"
      },
      "source": [
        "pose_input, upscale_bbox = detector_to_simple_pose(img, class_IDs, scores, bounding_boxs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2h0pHYeQmyI"
      },
      "source": [
        "predicted_heatmap = pose_net(pose_input)\r\n",
        "pred_coords, confidence = heatmap_to_coord(predicted_heatmap, upscale_bbox)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaAI0OfkQoxH"
      },
      "source": [
        "ax = utils.viz.plot_keypoints(img, pred_coords, confidence,\r\n",
        "                              class_IDs, bounding_boxs, scores,\r\n",
        "                              box_thresh=0.5, keypoint_thresh=0.2)\r\n",
        "plt.rcParams[\"figure.figsize\"] = (20,15)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8aHvY4LQ4fI"
      },
      "source": [
        "### AlphaPose Estimation\r\n",
        "- input size : 320*256"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7uXMCkjQ7SH"
      },
      "source": [
        "from matplotlib import pyplot as plt\r\n",
        "from gluoncv import model_zoo, data, utils\r\n",
        "from gluoncv.data.transforms.pose import detector_to_alpha_pose, heatmap_to_coord_alpha_pose"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KllPyTBWQ9ob"
      },
      "source": [
        "detector = model_zoo.get_model('yolo3_mobilenet1.0_coco', pretrained=True)\r\n",
        "pose_net = model_zoo.get_model('alpha_pose_resnet101_v1b_coco', pretrained=True)\r\n",
        "\r\n",
        "# Note that we can reset the classes of the detector to only include\r\n",
        "# human, so that the NMS process is faster.\r\n",
        "\r\n",
        "detector.reset_class([\"person\"], reuse_weights=['person'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-prxFwFRBTK"
      },
      "source": [
        "im_fname = utils.download('https://github.com/dmlc/web-data/blob/master/' +\r\n",
        "                          'gluoncv/pose/soccer.png?raw=true',\r\n",
        "                          path='soccer.png')\r\n",
        "x, img = data.transforms.presets.yolo.load_test(im_fname, short=512)\r\n",
        "print('Shape of pre-processed image:', x.shape)\r\n",
        "\r\n",
        "class_IDs, scores, bounding_boxs = detector(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "om0Y4GoHRBtL"
      },
      "source": [
        "pose_input, upscale_bbox = detector_to_alpha_pose(img, class_IDs, scores, bounding_boxs)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rmC9B2BRKnB"
      },
      "source": [
        "predicted_heatmap = pose_net(pose_input)\r\n",
        "pred_coords, confidence = heatmap_to_coord_alpha_pose(predicted_heatmap, upscale_bbox)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joh2crIHRMqv"
      },
      "source": [
        "ax = utils.viz.plot_keypoints(img, pred_coords, confidence,\r\n",
        "                              class_IDs, bounding_boxs, scores,\r\n",
        "                              box_thresh=0.5, keypoint_thresh=0.2)\r\n",
        "\r\n",
        "plt.rcParams[\"figure.figsize\"] = (20,15)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AviUQSXQsiY8"
      },
      "source": [
        "## Action Recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4e4SJ8TBgCN1"
      },
      "source": [
        "### TSN (UCF101)\r\n",
        "- Temporal Segment Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLRJ3gwyh9j7"
      },
      "source": [
        "#### TSN Framework\r\n",
        "<img src='https://blog.kakaocdn.net/dn/cPmbiR/btqI4UwbnXz/c6UOHFYP5ia2hdWbKH5lhk/img.png' width=100% />"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiBKf68nskhL"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import mxnet as mx\r\n",
        "from mxnet import gluon, nd, image\r\n",
        "from mxnet.gluon.data.vision import transforms\r\n",
        "from gluoncv.data.transforms import video\r\n",
        "from gluoncv import utils\r\n",
        "from gluoncv.model_zoo import get_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvlDTIg7gKpV"
      },
      "source": [
        "url = 'https://github.com/bryanyzhu/tiny-ucf101/raw/master/ThrowDiscus.png'\r\n",
        "im_fname = utils.download(url)\r\n",
        "\r\n",
        "img = image.imread(im_fname)\r\n",
        "\r\n",
        "plt.imshow(img.asnumpy())\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aE7z6wwlgQbp"
      },
      "source": [
        "transform_fn = transforms.Compose([\r\n",
        "    video.VideoCenterCrop(size=224),\r\n",
        "    video.VideoToTensor(),\r\n",
        "    video.VideoNormalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\r\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n31yMFU5gQ34"
      },
      "source": [
        "img_list = transform_fn([img.asnumpy()])\r\n",
        "plt.imshow(np.transpose(img_list[0], (1,2,0)))\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GX4-Vij2gSmg"
      },
      "source": [
        "net = get_model('vgg16_ucf101', nclass=101, pretrained=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUK6EXKOkzf9"
      },
      "source": [
        "#### TSN Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBoelvDgj0Mx"
      },
      "source": [
        "net.summary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2fueuPvgW8u"
      },
      "source": [
        "pred = net(nd.array(img_list[0]).expand_dims(axis=0))\r\n",
        "\r\n",
        "classes = net.classes\r\n",
        "topK = 5\r\n",
        "ind = nd.topk(pred, k=topK)[0].astype('int')\r\n",
        "print('The input video frame is classified to be')\r\n",
        "for i in range(topK):\r\n",
        "    print('\\t[%s], with probability %.3f.'%\r\n",
        "          (classes[ind[i].asscalar()], nd.softmax(pred)[0][ind[i]].asscalar()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuUZPVGNgb6k"
      },
      "source": [
        "from gluoncv.utils import try_import_cv2\r\n",
        "cv2 = try_import_cv2()\r\n",
        "\r\n",
        "url = 'https://github.com/bryanyzhu/tiny-ucf101/raw/master/v_Basketball_g01_c01.avi'\r\n",
        "video_fname = utils.download(url)\r\n",
        "\r\n",
        "cap = cv2.VideoCapture(video_fname)\r\n",
        "cnt = 0\r\n",
        "video_frames = []\r\n",
        "while(cap.isOpened()):\r\n",
        "    ret, frame = cap.read()\r\n",
        "    cnt += 1\r\n",
        "    if ret and cnt % 25 == 0:\r\n",
        "        video_frames.append(frame)\r\n",
        "    if not ret: break\r\n",
        "\r\n",
        "cap.release()\r\n",
        "print('We evenly extract %d frames from the video %s.' % (len(video_frames), video_fname))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6teibuQCgcnb"
      },
      "source": [
        "if video_frames:\r\n",
        "    video_frames_transformed = transform_fn(video_frames)\r\n",
        "    final_pred = 0\r\n",
        "    for _, frame_img in enumerate(video_frames_transformed):\r\n",
        "        pred = net(nd.array(frame_img).expand_dims(axis=0))\r\n",
        "        final_pred += pred\r\n",
        "    final_pred /= len(video_frames)\r\n",
        "\r\n",
        "    classes = net.classes\r\n",
        "    topK = 5\r\n",
        "    ind = nd.topk(final_pred, k=topK)[0].astype('int')\r\n",
        "    print('The input video is classified to be')\r\n",
        "    for i in range(topK):\r\n",
        "        print('\\t[%s], with probability %.3f.'%\r\n",
        "              (classes[ind[i].asscalar()], nd.softmax(final_pred)[0][ind[i]].asscalar()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9jmBrxDgsCh"
      },
      "source": [
        "### I3D (Kinetcis400)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qU0YlJ4elY3U"
      },
      "source": [
        "#### I3D Framework\r\n",
        "- Inflated 3D ConvNet\r\n",
        "<img src='https://www.researchgate.net/profile/Jamil_Ahmad13/publication/321352236/figure/fig6/AS:668725271351305@1536447937705/Framework-of-the-proposed-DB-LSTM-for-action-recognition-action-recognition-The-output.png' width=100% />"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ro-BNF2gg73"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import mxnet as mx\r\n",
        "from mxnet import gluon, nd, image\r\n",
        "from mxnet.gluon.data.vision import transforms\r\n",
        "from gluoncv.data.transforms import video\r\n",
        "from gluoncv import utils\r\n",
        "from gluoncv.model_zoo import get_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zK6xwghg2R8"
      },
      "source": [
        "from gluoncv.utils.filesystem import try_import_decord\r\n",
        "decord = try_import_decord()\r\n",
        "\r\n",
        "url = 'https://github.com/bryanyzhu/tiny-ucf101/raw/master/abseiling_k400.mp4'\r\n",
        "video_fname = utils.download(url)\r\n",
        "vr = decord.VideoReader(video_fname)\r\n",
        "frame_id_list = range(0, 64, 2)\r\n",
        "video_data = vr.get_batch(frame_id_list).asnumpy()\r\n",
        "clip_input = [video_data[vid, :, :, :] for vid, _ in enumerate(frame_id_list)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LP5l6Wjyg35a"
      },
      "source": [
        "transform_fn = video.VideoGroupValTransform(size=224, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\r\n",
        "clip_input = transform_fn(clip_input)\r\n",
        "clip_input = np.stack(clip_input, axis=0)\r\n",
        "clip_input = clip_input.reshape((-1,) + (32, 3, 224, 224))\r\n",
        "clip_input = np.transpose(clip_input, (0, 2, 1, 3, 4))\r\n",
        "print('Video data is downloaded and preprocessed.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLFmCtt4g5s-"
      },
      "source": [
        "model_name = 'i3d_inceptionv1_kinetics400'\r\n",
        "net = get_model(model_name, nclass=400, pretrained=True)\r\n",
        "print('%s model is successfully loaded.' % model_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zK1pgTFmXk6"
      },
      "source": [
        "#### I3D layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWKGO5H-mVH3"
      },
      "source": [
        "net.summary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXxdk-yIg7RC"
      },
      "source": [
        "pred = net(nd.array(clip_input))\r\n",
        "\r\n",
        "classes = net.classes\r\n",
        "topK = 5\r\n",
        "ind = nd.topk(pred, k=topK)[0].astype('int')\r\n",
        "print('The input video clip is classified to be')\r\n",
        "for i in range(topK):\r\n",
        "    print('\\t[%s], with probability %.3f.'%\r\n",
        "          (classes[ind[i].asscalar()], nd.softmax(pred)[0][ind[i]].asscalar()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFlFYXm4hA8P"
      },
      "source": [
        "### SlowFast (Kinetcis400)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnXfxWQhnmbc"
      },
      "source": [
        "#### SlowFast Framework\r\n",
        "<img src='https://miro.medium.com/max/700/0*WLTSCRGi1DNfqyyi.png' width=100% />"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iwd1mak1g9UU"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import mxnet as mx\r\n",
        "from mxnet import gluon, nd, image\r\n",
        "from mxnet.gluon.data.vision import transforms\r\n",
        "from gluoncv.data.transforms import video\r\n",
        "from gluoncv import utils\r\n",
        "from gluoncv.model_zoo import get_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBiH9b35hFpy"
      },
      "source": [
        "from gluoncv.utils.filesystem import try_import_decord\r\n",
        "decord = try_import_decord()\r\n",
        "\r\n",
        "url = 'https://github.com/bryanyzhu/tiny-ucf101/raw/master/abseiling_k400.mp4'\r\n",
        "video_fname = utils.download(url)\r\n",
        "vr = decord.VideoReader(video_fname)\r\n",
        "fast_frame_id_list = range(0, 64, 2)\r\n",
        "slow_frame_id_list = range(0, 64, 16)\r\n",
        "frame_id_list = list(fast_frame_id_list) + list(slow_frame_id_list)\r\n",
        "video_data = vr.get_batch(frame_id_list).asnumpy()\r\n",
        "clip_input = [video_data[vid, :, :, :] for vid, _ in enumerate(frame_id_list)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvxqjHPWhHbi"
      },
      "source": [
        "transform_fn = video.VideoGroupValTransform(size=224, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\r\n",
        "clip_input = transform_fn(clip_input)\r\n",
        "clip_input = np.stack(clip_input, axis=0)\r\n",
        "clip_input = clip_input.reshape((-1,) + (36, 3, 224, 224))\r\n",
        "clip_input = np.transpose(clip_input, (0, 2, 1, 3, 4))\r\n",
        "print('Video data is downloaded and preprocessed.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiax_I7OhJGd"
      },
      "source": [
        "model_name = 'slowfast_4x16_resnet50_kinetics400'\r\n",
        "net = get_model(model_name, nclass=400, pretrained=True)\r\n",
        "print('%s model is successfully loaded.' % model_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqE9VAfhn4O_"
      },
      "source": [
        "#### slowfast Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVf5s56YhZ_4"
      },
      "source": [
        "net.summary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXNICGvWhK-s"
      },
      "source": [
        "pred = net(nd.array(clip_input))\r\n",
        "\r\n",
        "classes = net.classes\r\n",
        "topK = 5\r\n",
        "ind = nd.topk(pred, k=topK)[0].astype('int')\r\n",
        "print('The input video clip is classified to be')\r\n",
        "for i in range(topK):\r\n",
        "    print('\\t[%s], with probability %.3f.'%\r\n",
        "          (classes[ind[i].asscalar()], nd.softmax(pred)[0][ind[i]].asscalar()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTPYxUDxwbyU"
      },
      "source": [
        "## Object Tracking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdmHD3F0weCy"
      },
      "source": [
        "### SiamRPN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TisFwx-2YJn"
      },
      "source": [
        "import os\r\n",
        "import argparse\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import mxnet as mx\r\n",
        "from gluoncv import model_zoo, utils\r\n",
        "from gluoncv.model_zoo.siamrpn.siamrpn_tracker import SiamRPNTracker as build_tracker\r\n",
        "from gluoncv.model_zoo.siamrpn.siamrpn_tracker import get_axis_aligned_bbox\r\n",
        "from gluoncv.utils.filesystem import try_import_cv2\r\n",
        "cv2 = try_import_cv2()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3Ty9pFqhNEI"
      },
      "source": [
        "from gluoncv import utils\r\n",
        "video_path = 'https://raw.githubusercontent.com/dmlc/web-data/master/gluoncv/tracking/Coke.mp4'\r\n",
        "im_video = utils.download(video_path)\r\n",
        "gt_bbox = [298, 160, 48, 80]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkH_H7cC2KWm"
      },
      "source": [
        "def read_data(video_path): \r\n",
        "    video_frames = [] \r\n",
        "    im_video = utils.download(video_path)\r\n",
        "    cap = cv2.VideoCapture(im_video)\r\n",
        "    while(True):\r\n",
        "        ret, img = cap.read()\r\n",
        "        if not ret:\r\n",
        "            break\r\n",
        "        video_frames.append(img)\r\n",
        "    \r\n",
        "    return video_frames"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmiAL3AM7GJI"
      },
      "source": [
        "def inference(video_frames, tracker, gt_bbox, save_dir): \r\n",
        "    scores = []\r\n",
        "    pred_bboxes = []\r\n",
        "    gt_bbox = list(map(int, gt_bbox))\r\n",
        "    if not os.path.exists(save_dir):\r\n",
        "        os.makedirs(save_dir)\r\n",
        "    for ind, frame in enumerate(video_frames):\r\n",
        "        if ind == 0:\r\n",
        "            cx, cy, w, h = get_axis_aligned_bbox(np.array(gt_bbox))\r\n",
        "            gt_bbox_ = [cx-(w-1)/2, cy-(h-1)/2, w, h]\r\n",
        "            tracker.init(frame, gt_bbox_, ctx=mx.cpu())\r\n",
        "            pred_bbox = gt_bbox_\r\n",
        "            scores.append(None)\r\n",
        "            pred_bboxes.append(pred_bbox)\r\n",
        "        else:\r\n",
        "            outputs = tracker.track(frame, ctx=mx.cpu())\r\n",
        "            pred_bbox = outputs['bbox']\r\n",
        "            pred_bboxes.append(pred_bbox)\r\n",
        "            scores.append(outputs['best_score'])\r\n",
        "        pred_bbox = list(map(int, pred_bbox))\r\n",
        "        cv2.rectangle(frame, (pred_bbox[0], pred_bbox[1]),\r\n",
        "                      (pred_bbox[0]+pred_bbox[2], pred_bbox[1]+pred_bbox[3]),\r\n",
        "                      (0, 255, 255), 3)\r\n",
        "        cv2.imwrite(os.path.join(save_dir, '%04d.jpg'%(ind+1)), frame)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4IYvtdB8KGM"
      },
      "source": [
        "net = model_zoo.get_model('siamrpn_alexnet_v2_otb15', ctx=mx.cpu(), pretrained=True)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2t356ln8Tz7"
      },
      "source": [
        "tracker = build_tracker(net)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jhlta4hN8eNI"
      },
      "source": [
        "video_path = 'https://raw.githubusercontent.com/dmlc/web-data/master/gluoncv/tracking/Coke.mp4'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOYPde1s8Yoz"
      },
      "source": [
        "video_frames = read_data(video_path)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uuf8gcdi8fph"
      },
      "source": [
        "# BGR -> RGB\r\n",
        "plt.imshow(video_frames[0][:,:,[2,1,0]])\r\n",
        "plt.show()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYc7zdNC8vDO"
      },
      "source": [
        "gt_bbox = [298, 160, 48, 80]\r\n",
        "save_dir = './predictions'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3_1fP8W8i0u"
      },
      "source": [
        "inference(video_frames, tracker, gt_bbox, save_dir) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgUBr6wo87x9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efX9Scg5GPmA"
      },
      "source": [
        "## 저장된 이미지 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDLDc64XGSVy"
      },
      "source": [
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-NyGGzuGePg"
      },
      "source": [
        "file_list = os.listdir(save_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iw2gyEu3GjNX"
      },
      "source": [
        "file_list.sort()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hn41VlLQHI_w"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import imageio\r\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXMcLB_6H3dU"
      },
      "source": [
        "def img_file_to_gif(img_root, img_files, output_file_name): \r\n",
        "    imgs_array = [np.array(imageio.imread(img_root + '/' + img_file)) for img_file in img_files] \r\n",
        "    imageio.mimsave(output_file_name, imgs_array, format='GIF', fps=24)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pdr5JZ0NIICs"
      },
      "source": [
        "img_file_to_gif(save_dir, file_list, \"coke_tracking.gif\")\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvmLpMICJFxC"
      },
      "source": [
        "- downsize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7d55yyFSB6m"
      },
      "source": [
        "!apt-get install -y gifsicle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdPE5M37Pk1U"
      },
      "source": [
        "!pip3 install pygifsicle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z62U0cl0RWTi"
      },
      "source": [
        "from pygifsicle import optimize\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYAcZEsERX2W"
      },
      "source": [
        "optimize(\"./coke_tracking.gif\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zFFZdGPyFG-"
      },
      "source": [
        "![coke](coke_tracking.gif)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiCrCQjvRufi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}